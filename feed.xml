<?xml version="1.0" encoding="utf-8"?><feed xmlns="http://www.w3.org/2005/Atom" xml:lang="en"><generator uri="https://jekyllrb.com/" version="4.4.1">Jekyll</generator><link href="https://jefferyy-peng.github.io/feed.xml" rel="self" type="application/atom+xml"/><link href="https://jefferyy-peng.github.io/" rel="alternate" type="text/html" hreflang="en"/><updated>2026-02-09T06:48:27+00:00</updated><id>https://jefferyy-peng.github.io/feed.xml</id><title type="html">blank</title><subtitle>A simple, whitespace theme for academics. Based on [*folio](https://github.com/bogoli/-folio) design. </subtitle><entry><title type="html">Generalization Through Variance in Diffusion Models</title><link href="https://jefferyy-peng.github.io/blog/2025/diffusion-generalization-variance/" rel="alternate" type="text/html" title="Generalization Through Variance in Diffusion Models"/><published>2025-05-21T16:40:16+00:00</published><updated>2025-05-21T16:40:16+00:00</updated><id>https://jefferyy-peng.github.io/blog/2025/diffusion-generalization-variance</id><content type="html" xml:base="https://jefferyy-peng.github.io/blog/2025/diffusion-generalization-variance/"><![CDATA[<p>”””</p> <p><strong>Formatting rules (per your request):</strong></p> <ul> <li>Every equation (inline or display) is wrapped in \(...\).</li> <li>I use LaTeX backslashes as single characters: I write $\text{like } \alpha_t$ as \(\alpha_t\), <strong>not</strong> \(\\alpha_t\).</li> <li>This writeup follows the <strong>logic of the paper</strong> and explicitly includes/answers the questions we discussed.</li> </ul> <hr/> <h2 id="0-high-level-roadmap-what-the-paper-tries-to-do">0. High-level roadmap (what the paper tries to do)</h2> <p>The paper’s main goal is to analytically characterize the <strong>typical learned sampling distribution</strong> of diffusion models trained with denoising score matching (DSM), and to explain <strong>why they generalize</strong> (place probability mass between training examples) instead of perfectly memorizing.</p> <p>Key steps:</p> <ol> <li>Define forward diffusion and reverse PF-ODE sampling.</li> <li>Compare the “true-score” objective \(J_0\) vs DSM objective \(J_1\).</li> <li>Show the proxy score is <strong>unbiased</strong> but has a structured <strong>covariance</strong>.</li> <li>Treat the trained score estimator \(\hat s_\theta\) as random (because it depends on finite training samples).</li> <li>Write PF-ODE sampling as a <strong>path integral</strong>, so that averaging over training randomness becomes tractable.</li> <li>Perform the ensemble average via cumulants, producing mean term \(M_1\) and covariance term \(M_2\) (the <strong>V-kernel</strong>).</li> <li>Under a Gaussian approximation, show the averaged dynamics are equivalent to an <strong>effective SDE</strong>: generalization happens iff the V-kernel is nonzero.</li> <li>Provide a toy “naive estimator” scheme showing how nonzero V-kernel arises even when using the proxy score directly.</li> </ol> <hr/> <h2 id="1-preliminaries-distributions-conditionals-and-marginals">1. Preliminaries: distributions, conditionals, and marginals</h2> <h3 id="11-data-distribution">1.1 Data distribution</h3> <p>Let \(x_0 \in \mathbb R^D\) denote clean data. The data distribution is \(p_{\text{data}}(x_0)\).</p> <p>A common idealization used in the paper is an empirical distribution over \(M\) examples \(\{\mu_m\}_{m=1}^M\): \(p_{\text{data}}(x_0) = \frac{1}{M}\sum_{m=1}^M \delta(x_0 - \mu_m).\)</p> <p>Here \(\delta(\cdot)\) is the Dirac delta distribution (we will define it precisely later).</p> <hr/> <h2 id="2-forward-diffusion-sde-why-the-minus-sign-and-closed-form-transition">2. Forward diffusion: SDE, why the minus sign, and closed-form transition</h2> <h3 id="21-forward-sde">2.1 Forward SDE</h3> <p>The forward process is an SDE: \(\dot x_t = -\beta_t x_t + G_t \eta_t,\quad t:0\to T.\) Definitions:</p> <ul> <li>\(x_t \in \mathbb R^D\): random variable at time \(t\).</li> <li>\(\dot x_t\): time derivative (informally; in SDE form it corresponds to Ito dynamics).</li> <li>\(\beta_t \ge 0\): scalar drift schedule.</li> <li>\(G_t \in \mathbb R^{D\times K}\): noise injection matrix.</li> <li>\(\eta_t\): standard Gaussian white noise process.</li> </ul> <p>Define diffusion tensor: \(D_t := \frac{G_t G_t^\top}{2}\in \mathbb R^{D\times D}.\)</p> <h4 id="your-question-why-negative-sign-if-t0-then-x_t---x_t">Your question: “why negative sign? if t=0 then x_t = -x_t?”</h4> <p>Important: the equation is about the <strong>derivative</strong>, not equality of values. At \(t=0\):</p> <ul> <li>you set initial condition \(x_0 \sim p_{\text{data}}\).</li> <li>the SDE gives derivative mean drift \(\dot x_0 = -\beta_0 x_0 + \text{noise}\). So it does <strong>not</strong> imply \(x_0 = -x_0\); it implies the drift points toward the origin (mean-reverting), preventing explosion and ensuring the process approaches noise.</li> </ul> <hr/> <h3 id="22-solve-the-forward-sde-derive-px_tmid-x_0tmathcal-nalpha_t-x_0-s_t">2.2 Solve the forward SDE: derive \(p(x_t\mid x_0,t)=\mathcal N(\alpha_t x_0, S_t)\)</h3> <p>We derive the conditional distribution of \(x_t\) given \(x_0\).</p> <p>Write the SDE in Ito differential form: \(dx_t = -\beta_t x_t dt + G_t dW_t,\) where \(W_t\) is a \(K\)-dim Brownian motion (so \(dW_t\) are Gaussian increments).</p> <h4 id="step-1-integrating-factor">Step 1: integrating factor</h4> <p>Define \(\alpha_t := \exp\left(-\int_0^t \beta_{t'} dt'\right).\) Note: \(\frac{d}{dt}\alpha_t = -\beta_t \alpha_t,\quad \alpha_0=1.\)</p> <p>Consider the scaled process: \(y_t := \alpha_t^{-1} x_t.\)</p> <p>Use Ito (here drift-only scaling works as usual since factor is deterministic): \(dy_t = d(\alpha_t^{-1} x_t) = \alpha_t^{-1} dx_t + x_t d(\alpha_t^{-1}).\) Compute: \(d(\alpha_t^{-1}) = -\alpha_t^{-2} d\alpha_t = -\alpha_t^{-2}(-\beta_t \alpha_t dt) = \beta_t \alpha_t^{-1} dt.\) So: \(dy_t = \alpha_t^{-1}(-\beta_t x_t dt + G_t dW_t) + x_t(\beta_t \alpha_t^{-1} dt) = \alpha_t^{-1} G_t dW_t.\)</p> <h4 id="step-2-integrate">Step 2: integrate</h4> <p>Integrate from 0 to t: \(y_t = y_0 + \int_0^t \alpha_{t'}^{-1} G_{t'} dW_{t'}.\) But \(y_0 = \alpha_0^{-1} x_0 = x_0\). Thus: \(y_t = x_0 + \int_0^t \alpha_{t'}^{-1} G_{t'} dW_{t'}.\)</p> <p>Multiply by \(\alpha_t\): \(x_t = \alpha_t x_0 + \alpha_t\int_0^t \alpha_{t'}^{-1} G_{t'} dW_{t'}.\)</p> <h4 id="step-3-identify-gaussian-distribution">Step 3: identify Gaussian distribution</h4> <p>The stochastic integral is Gaussian with mean 0. Thus conditional on \(x_0\):</p> <ul> <li>mean: \(\mathbb E[x_t\mid x_0] = \alpha_t x_0.\)</li> <li>covariance: Let \(\varepsilon_t := \alpha_t\int_0^t \alpha_{t'}^{-1} G_{t'} dW_{t'}.\) Then: \(\mathrm{Cov}(\varepsilon_t\mid x_0) = \alpha_t^2 \int_0^t \alpha_{t'}^{-2} G_{t'} \mathrm{Cov}(dW_{t'}) G_{t'}^\top.\) Since \(\mathrm{Cov}(dW_{t'}) = I dt'\): \(\mathrm{Cov}(\varepsilon_t\mid x_0) = \alpha_t^2 \int_0^t \alpha_{t'}^{-2} G_{t'} G_{t'}^\top dt' = \alpha_t^2 \int_0^t \alpha_{t'}^{-2} (2D_{t'}) dt'.\)</li> </ul> <p>Many texts rewrite this as an equivalent expression in terms of the forward-time convention used in the paper: \(S_t := \int_0^t 2D_{t'} \alpha_{t'}^2 dt'.\) (This matches the paper’s definition; it can be obtained by a change of variables depending on whether one defines \(\alpha_t\) relative to 0 or relative to t. The paper uses the above closed form.)</p> <p>Thus: \(p(x\mid x_0,t) = \mathcal N(x; \alpha_t x_0, S_t).\)</p> <hr/> <h3 id="23-derive-the-marginal-at-time-t">2.3 Derive the marginal at time \(t\)</h3> <p>Define the marginal: \(p(x\mid t) := \int p(x\mid x_0,t)\, p_{\text{data}}(x_0)\, dx_0.\)</p> <p><strong>Derivation:</strong> law of total probability / marginalization: \(p(x\mid t) = \int p(x,x_0\mid t)\, dx_0 = \int p(x\mid x_0,t)p_{\text{data}}(x_0)\, dx_0.\)</p> <p>If \(p_{\text{data}}\) is discrete mixture of deltas: \(p(x\mid t) = \frac{1}{M}\sum_{m=1}^M \mathcal N(x; \alpha_t \mu_m, S_t).\) So the forward marginal becomes a Gaussian mixture with components centered at scaled training examples.</p> <hr/> <h2 id="3-scores-true-score-and-proxy-score-with-full-derivations">3. Scores: true score and proxy score (with full derivations)</h2> <h3 id="31-true-score">3.1 True score</h3> <p>Define the true score: \(s(x,t) := \nabla_x \log p(x\mid t).\)</p> <p>This is the vector field needed by reverse-time sampling methods.</p> <hr/> <h3 id="32-proxy-score-dsm-target-and-its-closed-form">3.2 Proxy score (DSM target) and its closed form</h3> <p>Define proxy score: \(\tilde s(x,t;x_0) := \nabla_x \log p(x\mid x_0,t).\) Since: \(p(x\mid x_0,t)=\mathcal N(x; \mu, \Sigma),\quad \mu=\alpha_t x_0,\quad \Sigma=S_t,\) we compute: \(\log \mathcal N(x;\mu,\Sigma) = -\frac{D}{2}\log(2\pi) - \frac{1}{2}\log\det\Sigma - \frac{1}{2}(x-\mu)^\top \Sigma^{-1}(x-\mu).\) Differentiate w.r.t. \(x\): \(\nabla_x \log \mathcal N(x;\mu,\Sigma) = -\frac{1}{2}\nabla_x\left((x-\mu)^\top \Sigma^{-1}(x-\mu)\right).\) Using: \(\nabla_x\left((x-\mu)^\top A (x-\mu)\right)= 2A(x-\mu)\quad \text{for symmetric }A,\) we get: \(\nabla_x \log \mathcal N(x;\mu,\Sigma)= -\Sigma^{-1}(x-\mu) = \Sigma^{-1}(\mu-x).\) Substitute: \(\tilde s(x,t;x_0) = S_t^{-1}(\alpha_t x_0 - x).\)</p> <hr/> <h2 id="4-compare-objectives-j_0-vs-j_1-and-why-tilde-s-matters">4. Compare objectives \(J_0\) vs \(J_1\) and why \(\tilde s\) matters</h2> <h3 id="41-define-the-objectives">4.1 Define the objectives</h3> <p>Idealized objective: \(J_0(\theta) := \mathbb E_{t,x}\left[\frac{\lambda_t}{2}\|\hat s_\theta(x,t) - s(x,t)\|^2\right].\)</p> <p>DSM objective: \(J_1(\theta) := \mathbb E_{t,x_0,x}\left[\frac{\lambda_t}{2}\|\hat s_\theta(x,t) - \tilde s(x,t;x_0)\|^2\right].\)</p> <p>Here the sampling is:</p> <ul> <li> \[t\sim p(t)\] </li> <li> \[x_0\sim p_{\text{data}}(x_0)\] </li> <li> \[x\sim p(x\mid x_0,t)\] </li> </ul> <hr/> <h3 id="42-unbiasedness-derive-mathbb-e_x_0mid-xttilde-ss">4.2 Unbiasedness: derive \(\mathbb E_{x_0\mid x,t}[\tilde s]=s\)</h3> <p>We prove: \(\mathbb E_{x_0\mid x,t}[\tilde s(x,t;x_0)] = s(x,t).\)</p> <p>Start from definition: \(p(x\mid t)=\int p(x\mid x_0,t)p_{\text{data}}(x_0)\, dx_0.\) Differentiate w.r.t. \(x\): $$ \nabla_x p(x\mid t) = \int \nab_</p> <p>”””</p>]]></content><author><name></name></author><category term="sample-posts"/><category term="Learning"/><summary type="html"><![CDATA[Paper summary for "Generalization through Variance in Diffusion Models"]]></summary></entry><entry><title type="html">How Diffusion Models Work</title><link href="https://jefferyy-peng.github.io/blog/2025/diffusion-model/" rel="alternate" type="text/html" title="How Diffusion Models Work"/><published>2025-03-19T16:40:16+00:00</published><updated>2025-03-19T16:40:16+00:00</updated><id>https://jefferyy-peng.github.io/blog/2025/diffusion-model</id><content type="html" xml:base="https://jefferyy-peng.github.io/blog/2025/diffusion-model/"><![CDATA[<p>As part of my research into the mechanisms of compositionality in generative AI, I am conducting a review of the foundational literature surrounding Diffusion Models. While these models have achieved ubiquity in text-to-image generation, understanding their underlying mathematical formulations and architectural constraints is essential for addressing their current limitations in factorization and generalization.</p> <p>This post summarizes the theoretical framework of diffusion models, covering the probabilistic definitions, conditioning mechanisms, and the trade-offs between pixel-space and latent-space architectures.</p> <hr/> <h2 id="21-formulations-of-diffusion-models">2.1 Formulations of Diffusion Models</h2> <p>Diffusion models can be formalized through three primary frameworks: <strong>Denoising Diffusion Probabilistic Models (DDPMs)</strong>, <strong>Score-based Generative Models (SGMs)</strong>, and <strong>Stochastic Differential Equations (SDEs)</strong>.</p> <h3 id="211-denoising-diffusion-probabilistic-models-ddpms">2.1.1 Denoising Diffusion Probabilistic Models (DDPMs)</h3> <p>The DDPM framework defines a forward Markov chain that gradually adds Gaussian noise to data \(x_0\) until it approaches an isotropic Gaussian distribution \(x_T\). The transition kernel is defined as: \(q(x_t \mid x_{t-1})=\mathcal{N}\!\left(x_t;\sqrt{1-\beta_t}\,x_{t-1},\beta_t I\right),\) where \(\beta_t \in (0,1)\) controls the noise variance.</p> <p>Let \(\alpha_t := 1-\beta_t\) and \(\bar{\alpha}_t := \prod_{s=1}^{t} \alpha_s\). Then the marginal distribution is:</p> \[q(x_t \mid x_0)=\mathcal{N}\!\left(x_t;\sqrt{\bar{\alpha}_t}\,x_0,(1-\bar{\alpha}_t)I\right).\] <p>Using the reparameterization trick with \(\epsilon \sim \mathcal{N}(0,I)\), we can write:</p> \[x_t=\sqrt{\bar{\alpha}_t}\,x_0 + \sqrt{1-\bar{\alpha}_t}\,\epsilon.\] <p>The generative capability arises from learning a parameterized reverse Markov chain. The model estimates the transition kernel \(p_\theta(x_{t-1}\mid x_t)\) to iteratively denoise the latent variables:</p> \[p_\theta(x_{t-1} | x_t) = \mathcal{N}(x_{t-1}; \mu_\theta(x_t, t), \Sigma_\theta(x_t, t))\] <p>Training is typically performed by optimizing a variational lower bound (ELBO) on the negative log-likelihood.</p> <blockquote> <p><strong>Step 1</strong>: Marginalize likelihood: the probability of \(x_0\) is obtained by integrating out all latent variables \(x_{1:T}\). This integral is generally intractable.</p> \[\mathbb{E}\big[-\log p_\theta(x_0)\big] = \mathbb{E}\left[-\log \int p_\theta(x_{0:T}) \, dx_{1:T}\right]\] <p><strong>Step 2</strong>: Introduce an auxiliary (variational) distribution \(q(x_{1:T}\mid x_0)\) by multiplying and dividing inside the integral.</p> \[= \mathbb{E}\left[ -\log \int p_\theta(x_{0:T}) \frac{q(x_{0:T})}{q(x_{0:T})} \, dx_{1:T} \right]\] <p><strong>Step 3</strong>: Apply Jensen’s inequality \(-\log\) is convex, moving the log inside the expectation. This produces an upper bound on the negative log-likelihood.</p> \[\le \mathbb{E}_q\left[ -\log \frac{p_\theta(x_{0:T})}{q(x_{1:T}\mid x_0)} \right]\] <p><strong>Step 4</strong>: Next, factorize the model and variational distributions</p> \[p_\theta(x_{0:T}) = p(x_T)\prod_{t=1}^{T} p_\theta(x_{t-1}\mid x_t), \quad q(x_{1:T}\mid x_0) = \prod_{t=1}^{T} q(x_t\mid x_{t-1})\] <p><strong>Step 5</strong>: Substituting these factorizations:</p> \[= \mathbb{E}_q\left[ -\log p(x_T)- \sum_{t=1}^{T} \log \frac{p_\theta(x_{t-1}\mid x_t)} {q(x_t\mid x_{t-1})} \right] := \mathcal{L}\] <p>The first term \(\mathbb{E}_q[-\log p(x_T)]\) is fixed and not optimizable, so we optimize the second term:</p> \[\mathbb{E}_{q(x_{t-1}, x_t)} \left[ \log \frac{q(x_t \mid x_{t-1})} {p_\theta(x_{t-1} \mid x_t)} \right] = \mathbb{E}_{q(x_0, x_t)} \Big[ \mathrm{KL}\big( q(x_{t-1} \mid x_t, x_0) \;\|\; p_\theta(x_{t-1} \mid x_t) \big) \Big]+\text{const}\] <p>this is equavalent to a noise-prediction objective, where a neural network \(\epsilon_\theta\) (typically a UNet) minimizes the error between the added noise \(\epsilon\) and the predicted noise:</p> \[L = \mathbb{E} [ \lambda(t)||\epsilon - \epsilon_\theta(x_t, t)||^2 ]\] </blockquote> <h3 id="212-score-based-generative-models-sgms-and-sdes">2.1.2 Score-based Generative Models (SGMs) and SDEs</h3> <p>Alternative formulations focus on the gradient of the log-density of the data instead of noise being added, known as the score function \(\nabla_x \log p(x)\).</p> <ul> <li><strong>SGMs:</strong> In score-based generative modeling, we train a <strong>Noise-Conditioned Score Network (NCSN)</strong> \(s_\theta(x,t)\) to approximate the score (gradient of the log-density) of data corrupted by Gaussian noise. The classical score-matching objective is</li> </ul> \[\frac{1}{2}\,\mathbb{E}_{p_{\text{data}}} \big\| s_\theta(x) - \nabla_x \log p_{\text{data}}(x) \big\|^2 .\] <p>Let \(x_0 \sim q(x_0)\) denote clean data, and define a family of noisy distributions via</p> \[q(x_t \mid x_0) = \mathcal{N}(x_t; x_0, \sigma_t^2 I), \qquad q(x_t) = \int q(x_t \mid x_0) q(x_0)\,dx_0 .\] <p>Conditioning the score network on the noise level \(t\), the score-matching objective becomes (up to a constant factor):</p> \[\mathbb{E}_{t \sim \mathcal{U}[1,T],\, x_0 \sim q(x_0),\, x_t \sim q(x_t \mid x_0)} \left[\lambda(t)\, \big\| s_\theta(x_t, t) - \nabla_x \log q(x_t \mid x_0) \big\|^2 \right].\] <p>The relation between DDPM and SGM is then</p> \[\boxed{ \epsilon_\theta(x,t) = -\,\sigma_t\, s_\theta(x,t) }\] <ul> <li><strong>SDEs:</strong> While DDPMs and SGMs are originally defined using a <strong>finite, discretized noising process</strong>, the diffusion process can be equivalently formulated in <strong>continuous time</strong> as a stochastic differential equation (SDE). This continuous view unifies diffusion models and enables flexible sampling algorithms.</li> </ul> <h4 id="general-forward-diffusion-sde">General Forward Diffusion SDE</h4> <p>The forward noising process is described by the <strong>Score SDE</strong>:</p> \[dx = f(x,t)\,dt + g(t)\,dw,\] <p>where:</p> <ul> <li>\(f(x,t)\) is the <strong>drift (diffusion) term</strong>,</li> <li>\(g(t)\) controls the <strong>noise magnitude</strong>,</li> <li>\(w\) is a standard Wiener process.</li> </ul> <p>This SDE defines a family of marginal distributions \(q_t(x)\) over time.</p> <h4 id="ddpm-as-a-special-case">DDPM as a Special Case</h4> <p>The continuous-time limit of DDPM corresponds to the SDE:</p> \[dx = -\frac{1}{2}\beta(t)\,x\,dt + \sqrt{\beta(t)}\,dw,\] <p>where \(\beta(t)\) is a continuous noise schedule. This formulation mirrors the discrete DDPM noising process in the limit of infinitely many steps.</p> <h4 id="sgm-as-a-special-case">SGM as a Special Case</h4> <p>Score-based Generative Models (SGMs) correspond to the SDE:</p> \[dx = \sqrt{\frac{d[\sigma_t^2]}{dt}}\,dw,\] <p>where \(\sigma(t)\) is the continuous noise scale. Here, the forward process is a pure diffusion without drift.</p> <h4 id="reverse-time-sde-sampling-process">Reverse-Time SDE (Sampling Process)</h4> <p>For any forward SDE of the form above, the <strong>reverse-time SDE</strong> is given by:</p> \[dx = \big[f(x,t) - g(t)^2 \nabla_x \log q_t(x)\big]\,dt + g(t)\,d\bar{w},\] <p>where:</p> <ul> <li>\(\nabla_x \log q_t(x)\) is the <strong>score function</strong>,</li> <li>\(\bar{w}\) is a backward-time Wiener process.</li> </ul> <p>Learning the score function enables generation of samples by simulating this reverse SDE.</p> <h4 id="probability-flow-ode">Probability Flow ODE</h4> <p>In addition to the reverse SDE, there exists an equivalent <strong>deterministic ODE</strong> with identical marginal distributions:</p> \[dx = \left[f(x,t) - \frac{1}{2}g(t)^2 \nabla_x \log q_t(x)\right]\,dt.\] <p>This <strong>probability flow ODE</strong> allows sampling without stochasticity, using standard ODE solvers.</p> <h4 id="sampling-methods">Sampling Methods</h4> <p>Given the learned score function, samples can be generated using:</p> <ul> <li>Reverse-time SDE solvers,</li> <li>Probability flow ODE solvers,</li> <li>Annealed Langevin Dynamics,</li> <li>Predictor–Corrector (PC) samplers combining SDE solvers with MCMC methods (e.g., Langevin MCMC or HMC).</li> </ul> <h2 id="22-conditional-generation-mechanisms">2.2 Conditional Generation Mechanisms</h2> <table> <tbody> <tr> <td>To enable controllable generation (e.g., text-to-image synthesis), diffusion models must incorporate a conditional vector $c$. The reverse process is modified to $p_\theta(x_{t-1}</td> <td>x_t, c)$. Two primary guidance methods dominate the literature:</td> </tr> </tbody> </table> <h3 id="221-classifier-guidance">2.2.1 Classifier Guidance</h3> <p>This approach leverages an auxiliary classifier $p_\phi(c | x_t)$ trained on noisy images. The denoising process can be expressed: \(p_{\theta,\phi}(x_t \mid x_{t+1}, c)=Z \, p_\theta(x_t \mid x_{t+1}) \, p_\phi(c \mid x_t)\) where \(Z\) is a normalization constant. Taking the gradient of the log of the conditional density (ignoring \(Z\)):</p> \[\nabla_{x_t} \log \big( p_\theta(x_t \mid x_{t+1}) \, p_\phi(c \mid x_t) \big)=\nabla_{x_t} \log p_\theta(x_t \mid x_{t+1}) + \nabla_{x_t} \log p_\phi(c \mid x_t).\] <p>Using the relationship between score and noise prediction,</p> \[\epsilon_\theta(x_t, t) = -\sigma_t s_\theta(x_t, t),\] <p>the gradient becomes:</p> <p>\(=-\frac{1}{\sigma_t}\,\epsilon_\theta(x_t, t)+\nabla_{x_t} \log p_\phi(c \mid x_t).\)</p> <blockquote> <p><strong>Key Intuition:</strong> beside the original unconditional score function, the gradient of the classifier is added to guide the denoise process.</p> </blockquote> <h3 id="222-classifier-free-guidance">2.2.2 Classifier-free Guidance</h3> <p>To avoid the computational cost and complexity of training a separate noise-robust classifier, Ho and Salimans (2022) proposed classifier-free guidance. Here, a single diffusion model is trained to handle both conditional and unconditional inputs (where $c = \emptyset$). During sampling, the noise prediction is a linear combination of both outputs, weighted by a scale $w$:</p> \[\tilde{\epsilon}_\theta(x_t, c) = (1 + w)\epsilon_\theta(x_t, c) - w\epsilon_\theta(x_t)\] <p>This method implicitly maximizes the probability of the condition without an external classifier and has become the standard for state-of-the-art models.</p> <blockquote> <p><strong>Key Intuition:</strong> trains one diffusion model to operate in two modes: with condition and without condition. During sampling, the model compares these two predictions. The difference tells you how the condition should push the sample, and scaling that difference lets you control how strongly the generation follows the condition. In effect, the model learns its own “internal classifier gradient” and uses it to guide sampling—without ever training an explicit classifier.</p> </blockquote> <h2 id="23-state-of-the-art-architectures">2.3 State-of-the-Art Architectures</h2> <p>Current text-to-image systems are generally categorized by whether the diffusion process occurs in pixel space or latent space.</p> <h3 id="231-pixel-based-models">2.3.1 Pixel-based Models</h3> <p>These models operate directly on high-dimensional image data.</p> <ul> <li><strong>GLIDE:</strong> Uses classifier-free guidance to generate photorealistic images and demonstrates capabilities in text-guided inpainting [15].</li> <li><strong>Imagen:</strong> A key finding from the development of Imagen is the scaling law regarding text encoders. The authors discovered that increasing the size of the language model (e.g., using T5-XXL) yields greater improvements in image fidelity and image-text alignment than increasing the size of the visual diffusion model itself [16].</li> </ul> <h3 id="232-latent-based-models">2.3.2 Latent-based Models</h3> <p>To address the high computational costs of pixel-space diffusion, <strong>Latent Diffusion Models (LDMs)</strong> utilize an autoencoder to project data into a lower-dimensional latent space [18].</p> <ul> <li><strong>Stable Diffusion:</strong> Applies the diffusion process within this compressed latent space, utilizing cross-attention mechanisms to incorporate text conditioning. This architecture significantly improves inference efficiency [19].</li> <li><strong>DALL-E 2 (unCLIP):</strong> Utilizes the CLIP embedding space. It generates an image embedding from text and then decodes this embedding into an image, leveraging the joint multimodal space learned by CLIP [20].</li> </ul> <h2 id="24-failure-modes-and-limitations">2.4 Failure Modes and Limitations</h2> <p>Despite the fidelity of these models, systematic evaluations reveal persistent limitations in their reasoning capabilities:</p> <ol> <li><strong>Attribute Binding:</strong> Models frequently fail to correctly bind attributes to objects. For example, in a prompt specifying a “red cube” and a “blue cube,” DALL-E 2 may swap the colors or textures [22], [23].</li> <li><strong>Text Rendering:</strong> While semantic understanding is high, the ability to render coherent alphanumeric text remains poor, likely due to tokenization schemes (BPE encoding) that obscure spelling information from the model [23], [24].</li> <li><strong>Physical Consistency:</strong> Generated images often exhibit violations of physical laws, such as incorrect shadow placement or reflections that do not align with the object’s geometry [25].</li> <li><strong>Bias toward Canonical Forms:</strong> When prompted with unusual scenarios (e.g., “a car with triangular wheels”), models often revert to the mean of the training distribution (circular wheels), indicating a lack of true compositional generalization [26].</li> </ol> <p>These failure modes suggest that while diffusion models excel at texture synthesis and semantic association, they struggle with precise factorization and compositional reasoning—a core focus of the subsequent chapters of this thesis [27].</p>]]></content><author><name></name></author><category term="sample-posts"/><category term="Learning"/><summary type="html"><![CDATA[A learning notebook for diffusion models]]></summary></entry></feed>